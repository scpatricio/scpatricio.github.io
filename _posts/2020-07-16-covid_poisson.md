---
title: "how can i modeling the covid pandemic?"
date: 2020-07-16
tags: [statistic, modeling]
header:
  image: "/images/likelihood/head.jpeg"
excerpt: "what is it?"
---

Se voce ainda nao percebeu, nÃ³s estamos em meio a uma pandemia (atÃ©
agora a maior deste sÃ©culo), e com uma doenÃ§a numa escala global vem o
acesso Ã  uma quantidade massiva de dados. E o que queremos fazer com
isso? Modelagem! Ã“bvio.

EntÃ£o sim, neste post irei comentar um pouco sobre a modelagem dos dados
da covid, especialmente do ponto de vista teÃ³rico, e tambÃ©m falar um
pouquinho sobre os problemas que podemos ter quando tentamos modelar os
dados do Brasil.

Para comeÃ§ar, vamos definir que *Y*<sub>*t*</sub> representa o nÃºmero
total de casos no dia *t*, onde representa a quantidade de dias desde o
primeiro caso. E considerar que ğ”¼(*Y*<sub>*t*</sub>)â€„=â€„*Î»*(*t*) , ou
seja, em mÃ©dia teremos que *Y*<sub>*t*</sub> assume um valor *Î»*(*t*).

Agora vamos conversar um pouco sobre *Î»*(*t*). Podemos assumir que
*Î»*(*t*)â€„=â€„*N*<sub>0</sub>*F*(*t*), onde *F*(*t*) Ã© alguma distribuiÃ§Ã£o
acumulada. Podemos assumir vÃ¡rias formas para *F*(*t*), tudo depende dos
dados e do comportamento da pandemia em outros paÃ­ses que jÃ¡ passaram
por ela.

Mais especificamente, teremos que a distribuiÃ§Ã£o acumulada *F*(*t*) estÃ¡
associada a um parÃ¢metro *Î¸*â€„âˆˆâ€„*Î˜*, que teremos que estimar. EntÃ£o,
agora temos
*Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>)â€„=â€„*N*<sub>0</sub>*F*(*t*;â€†*Î¸*), e o que
nos resta Ã© estimar o parÃ¢metro
*Î¸*<sup>\*</sup>â€„=â€„(*N*<sub>0</sub>,â€†*Î¸*)â€². Essa estimativa pode ser
realizada de vÃ¡rias formas, deixa eu comentar alguma delas.

A primeira delas Ã© buscar o valor mais pausÃ­vel de *Î¸*<sup>\*</sup>
minimizando a distancia entre ğ”¼(*Y*<sub>*t*</sub>) e
*Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>), o famoso mÃ©todo de mÃ­nimos quadrados. O
problema de usar esse mÃ©todo destes dados, Ã© que ele modela apenas a
mÃ©dia, ignorando o fato de que a variÃ¢ncia de *Y*<sub>*t*</sub> aumenta
junto com a mÃ©dia, ou seja, quanto maior o valor obervado de
*Y*<sub>*t*</sub>, maior serÃ¡ sua variÃ¢ncia.

Uma forma de contornar esse problema Ã© utilizar o mÃ©todo de mÃ­nimos
quadrados ponderados e minimzar a distancia entre
*Y*<sub>*t*</sub>/*Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>). Esse mÃ©todo acaba
estabilizando a variaÃ§Ã£o observada nos dados, mas por fim estamos
modelando apenas a variaÃ§Ã£o dos dados, ao invÃ©s da mÃ©dia em si, jÃ¡ que
assim temos ğ”¼\[*Y*<sub>*t*</sub>/*Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>)\]â€„=â€„1.

Entao uma forma de modelarmos a mÃ©dia e variaÃ§Ã£o dos dados ao mesmo
tempo, Ã© assumir que *Y*<sub>*t*</sub> possua distribuissÃ£o poisson com
parÃ¢metro *Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>) - normalmente usamos a notaÃ§Ã£o
*Y*<sub>*t*</sub>â€„âˆ¼â€„*P**o**i**s*(*Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>)) -
porque daÃ­ temos que
ğ”¼(*Y*<sub>*t*</sub>)â€„=â€„ğ•ğ”¸â„(*Y*<sub>*t*</sub>)â€„=â€„*Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>),
ou seja, consideramos que a variÃ¢ncia aumenta junto com a mÃ©dia dos
valores observados, mais especificamente, aumenta na mesma proporÃ§Ã£o.

EntÃ£o, assumindo
*Y*<sub>*t*</sub>â€„âˆ¼â€„*P**o**i**s*(*Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>)),
podemos estimar *Î¸*<sup>\*</sup>â€„=â€„(*N*<sub>0</sub>,â€†*Î¸*)â€² via o mÃ©todo
de mÃ¡xima verossimilhanÃ§a. EntÃ£o vamos Ã  ele:

Como assumidos que
*Y*<sub>*t*</sub>â€„âˆ¼â€„*P**o**i**s*(*Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>)),
assumimos que

$$
\\mathbb{P}(Y\_t = k) = \\frac{exp\\{ -\\lambda(t; \\theta, N\_0)\\}\[\\lambda(t; \\theta, N\_0)\]^k}{k!},
$$
e consequentemente, a funÃ§Ã£o de verossmilhanÃ§a vai ser dada por:

$$
L(\\theta, N\_0; Y\_t = y\_t) = \\prod\_{t =0}^n \\frac{exp\\{ -\\lambda(t; \\theta, N\_0)\\}\[\\lambda(t; \\theta, N\_0)\]^{y\_t}}{y\_t!}.
$$

Simples, nÃ©?! EntÃ£o vamos Ã  estimaÃ§Ã£o via mÃ¡xima verossimilhanÃ§a., que Ã©
basicamente maximizar
*L*(*Î¸*,â€†*N*<sub>0</sub>;â€†*Y*<sub>*t*</sub>â€„=â€„*y*<sub>*t*</sub>) ou
â„“(*Î¸*,â€†*N*<sub>0</sub>;â€†*Y*<sub>*t*</sub>â€„=â€„*y*<sub>*t*</sub>)â€„=â€„logâ€†*L*(*Î¸*,â€†*N*<sub>0</sub>;â€†*Y*<sub>*t*</sub>â€„=â€„*y*<sub>*t*</sub>),
que Ã© dada por

$$
\\hat{\\theta}\* = \\max\_{\\theta^\* = (\\theta, N\_0)'}\\sum\_{t=0}^n y\_t \\log \[\\lambda(t; \\theta, N\_0)\] - \\lambda(t; \\theta, N\_0).
$$
Pronto, agora Ã© sÃ³ inserir os dados, e maximizar. Todo o problema
complexo de modelagem foi resumido Ã  um problema de otimizaÃ§Ã£o.

Pontos interessantes
--------------------

Ok, digamos que jÃ¡ estimamos o vator de parÃ£metros
*Î¸*<sup>\*</sup>â€„=â€„(*Î¸*,â€†*N*<sub>0</sub>)â€². Vamos responder algumas
perguntas de interesse:

### No final, quantas pessoas serÃ£o contaminadas?

Ah, essa pergunta Ã© simples de responder ! Basta tomarmos o limite
quando *t*â€„â†’â€„âˆ. Dessa forma, temos
lim<sub>*t*â€„â†’â€„âˆ</sub>*Î»*(*t*;â€†*Î¸*,â€†*N*<sub>0</sub>)â€„=â€„lim<sub>*t*â€„â†’â€„âˆ</sub>*N*<sub>0</sub>*F*(*t*;â€†*Î¸*)â€„=â€„*N*<sub>0</sub>.
EntÃ£o no final da pandemia teremos *N*<sub>0</sub> pessoas contaminadas.

### Como eu faÃ§o previsÃ£o?

EntÃ£o, a previsÃ£o Ã© mais simples do que vocÃª imagina. Se voce quiser
fazer a previsÃ£o para o tempo *t*â€…+â€…*k*, basta tomar como previsÃ£o o
valor esperado de *Y*<sub>*t*â€…+â€…*k*</sub> dado os dados que jÃ¡
observamos {*Y*<sub>*k*</sub>â€„:â€„*k*â€„=â€„0,â€†â€¦,â€†*t*}, ou seja,
ğ”¼\[*Y*<sub>*t*â€…+â€…1</sub>|{*Y*<sub>*k*</sub>â€„:â€„*k*â€„=â€„0,â€†â€¦,â€†*t*}\]â€„=â€„*Î»*(*t*â€…+â€…*k*;â€†*Î¸*,â€†*N*<sub>0</sub>)
.

### Como calculo a taxa de reprodutibilidade (*R*<sub>0</sub>)?

No tempo *t*, podemos definir o *R*<sub>0</sub> como sendo
$$
R\_0 = \\frac{\\lambda(t; \\theta, N\_0)-\\lambda(t-1; \\theta, N\_0)}{\\lambda(t-1; \\theta, N\_0)}.
$$

### E o nÃºmero mÃ©dio de novos casos?

EntÃ£o, esse tambÃ©m Ã© bem simples, Ã© apenas a diferenÃ§a no valor esperado
de *Y* nos tempos *t*â€…+â€…*k* e *t*â€…+â€…*k*â€…âˆ’â€…1:
*n*<sub>*t*â€…+â€…*k*</sub>â€„=â€„ğ”¼\[*Y*<sub>*t*â€…+â€…*k*</sub>â€…âˆ’â€…*Y*<sub>*t*â€…+â€…*k*â€…âˆ’â€…1</sub>\]â€„=â€„*Î»*(*t*â€…+â€…*k*;â€†*Î¸*,â€†*N*<sub>0</sub>)â€…âˆ’â€…*Î»*(*t*â€…+â€…*k*â€…âˆ’â€…1;â€†*Î¸*,â€†*N*<sub>0</sub>)

Bom, espero que vocÃª tenha conseguido entender a ideia por trÃ¡s desta
modelagem. Podemos usar-la nÃ£o somente para modelar os dados de novos
casos, mas tambÃ©m a contagem de Ã³bitos. E isso nÃ£o se restringe Ã  dados
de pandemias, mas existem vÃ¡rios outros problemas que podem ser
abordados dessa forma, inclusive quando fazemos inferencia estatÃ­stica
utilizando tÃ¡buas de vida, o que Ã© muito comum na demografia e tambÃ©m em
ciencias atuariais.

Mas voltando Ã  falar da pandemia, especificamente sobre os dados do
Brasil. Querer representar o comportamento da pandemia no Brasil apenas
com um modelo, Ã© um tanto quanto pretencioso. O Brasil Ã© um paÃ­s com
dimensÃµes continentais e extremamente heterogÃªnio. Essa heterogeneidade
faz com que um Ãºnico modelo nÃ£o seja capaz de representar a dinÃ¢mica
comportamental da COVID-19 no Brasil, por isso o recomendado Ã© utilizar
um modelo de misturas para modelar esses dados, e considerar as regiÃµes,
ou estados, como clusteres, atribuÃ­ndo Ã  eles sua prÃ³pria curva
epidemiolÃ³gica.

Neste post eu quis apenas apresentar uma forma de modelar esses dados e
fazer previsÃµes. Em breve farei mais um post com um hands-on nos dodos.
Vejo vocÃª lÃ¡ !
